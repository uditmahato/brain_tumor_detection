{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "large-cleaner",
   "metadata": {
    "papermill": {
     "duration": 0.031315,
     "end_time": "2021-08-12T12:50:34.735318",
     "exception": false,
     "start_time": "2021-08-12T12:50:34.704003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-bracelet",
   "metadata": {
    "papermill": {
     "duration": 0.030098,
     "end_time": "2021-08-12T12:50:34.795898",
     "exception": false,
     "start_time": "2021-08-12T12:50:34.765800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook, I've used **CNN** to perform Image Classification on the Brain Tumor dataset.<br>\n",
    "Since this dataset is small, if we train a neural network to it, it won't really give us a good result.<br>\n",
    "Therefore, I'm going to use the concept of **Transfer Learning** to train the model to get really accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-completion",
   "metadata": {
    "papermill": {
     "duration": 0.030921,
     "end_time": "2021-08-12T12:50:35.100161",
     "exception": false,
     "start_time": "2021-08-12T12:50:35.069240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "super-artist",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 6.777938,
     "end_time": "2021-08-12T12:50:41.909603",
     "exception": false,
     "start_time": "2021-08-12T12:50:35.131665",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import efficientnet_b0\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-sheep",
   "metadata": {
    "papermill": {
     "duration": 0.061658,
     "end_time": "2021-08-12T12:50:42.179796",
     "exception": false,
     "start_time": "2021-08-12T12:50:42.118138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coated-africa",
   "metadata": {
    "papermill": {
     "duration": 0.340312,
     "end_time": "2021-08-12T12:50:42.583653",
     "exception": false,
     "start_time": "2021-08-12T12:50:42.243341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC8ElEQVR4nO3asU4iARSF4QsaSYxAtESo7Gx8A1sfyze1cBIeQIiFicwWGzfZAh3IMbPjfl/LFCfX4s+Ao7Zt2wKAoHHfAwD4ecQFgDhxASBOXACIExcA4sQFgDhxASDutMtDu92u1ut1TafTGo1G370JgH9U27a12WxqsVjUeLz//aRTXNbrda1Wq9g4AIataZpaLpd7P+8Ul+l0WlVV19fXn5aKv11eXvY9YZDu7u76njBIDw8PfU8YnNvb274nDM52u637+/s/XdinU1w+vgobj8ficoCTk5O+JwzS2dlZ3xMG6fz8vO8Jg3NxcdH3hMH66icSpQAgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEg7rTLQ23bVlXVbrf71jE/zfv7e98TBunt7a3vCYP0+vra94TB2W63fU8YnI+bfXRhn1H71RNV9fT0VDc3N5llAAxe0zS1XC73ft7pzeXq6qqqqp6fn2s+n2eW/QdeXl5qtVpV0zQ1m836njMIbnYcdzucmx2nbdvabDa1WCw+fa5TXMbj3z/NzOdzf4QjzGYzdzuQmx3H3Q7nZofr8pLhB30A4sQFgLhOcZlMJvX4+FiTyeS79/wo7nY4NzuOux3Ozb5Xp/8WA4BD+FoMgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4n4BnrNuSvMY+NgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC+UlEQVR4nO3aT4rTcBjH4be1GlDbwqyktAsZcKEn8AJ6AvU4c9NZTKAHmDqCf2hcDKgI1bR8h5jxeVaB/BYvbxcfknTSdV1XABA0HXoAAO4fcQEgTlwAiBMXAOLEBYA4cQEgTlwAiJv1ObTf72u73dZ8Pq/JZHLXMwHwj+q6rna7Xa1Wq5pODz+f9IrLdrutzWYTGw6AcWvbttbr9cH7veIyn89vL14/q5p5k9bXm1cvhh5hlGaP90OPMErnb54PPcLofHj5fugRRudm96nevnr3swsH9IrLj1dhs2lNxKW3h02v9fKbWSMup2iePBp6hNF5ungy9Aij9bdPJEoBQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQNysz6Gu624vvu2ru8tp7pmvn78NPcIodQ/2Q48wSp9vvgw9wuh8vL4ZeoTRudl9qqpfunDApPvbiaq6vLys8/PzzGQAjF7btrVerw/e7/XkcnZ2VlVVV1dXtVwuM5P9B66vr2uz2VTbtrVYLIYeZxTs7DT2djw7O03XdbXb7Wq1Wv3xXK+4TKe3n2aWy6Uf4QSLxcLejmRnp7G349nZ8fo8ZPigD0CcuAAQ1ysuTdPUxcVFNU1z1/PcK/Z2PDs7jb0dz87uVq9/iwHAMbwWAyBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjvKtBvVfO0ce0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC+0lEQVR4nO3av27aYBSH4QMkQqkKVEhdEEyZO7RL915I1TvJnWaIJS4AqnSIgjv0j9SB1KBf5Dp9ntUejg6gV5/NqG3btgAgaNz3AAC8POICQJy4ABAnLgDEiQsAceICQJy4ABB30eWmw+FQ2+22ZrNZjUaj554JgH9U27a13+9rtVrVeHz8fNIpLtvttjabTWw4AIataZpar9dHr3eKy2w2q6qqd2/e1MTJpbPr5bLvEQbp027X9wiD9OHjx75HGJy3nz/3PcLg7O/v6/2XL7+7cEynuPx6FDYZjWryxDGIP11OJn2PMEhXvmNneX152fcIgzN79arvEQbrb69I/IoBiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiLvoclPbtlVV9di2VYfDsw70kjw8PvY9wiB98x07y9eHh75HGJyr+/u+Rxic/c+d/erCMaP2b3dU1e3tbV1fX2cmA2Dwmqap9Xp99Hqnk8tyuayqqru7u1osFpnJ/gO73a42m001TVPz+bzvcQbBzs5jb6ezs/O0bVv7/b5Wq9WT93WKy3j849XMYrHwIZxhPp/b24ns7Dz2djo7O12XQ4YX+gDEiQsAcZ3iMp1O6+bmpqbT6XPP86LY2+ns7Dz2djo7e16d/i0GAKfwWAyAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDivgN0oHFgMtTbswAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
    "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
    "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n",
    "\n",
    "sns.palplot(colors_dark)\n",
    "sns.palplot(colors_green)\n",
    "sns.palplot(colors_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-immigration",
   "metadata": {
    "papermill": {
     "duration": 0.064673,
     "end_time": "2021-08-12T12:50:42.840614",
     "exception": false,
     "start_time": "2021-08-12T12:50:42.775941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "italian-identity",
   "metadata": {
    "papermill": {
     "duration": 0.072914,
     "end_time": "2021-08-12T12:50:42.976596",
     "exception": false,
     "start_time": "2021-08-12T12:50:42.903682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-israel",
   "metadata": {
    "papermill": {
     "duration": 0.06252,
     "end_time": "2021-08-12T12:50:43.103425",
     "exception": false,
     "start_time": "2021-08-12T12:50:43.040905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start off by appending all the images from the  directories into a Python list and then converting them into numpy arrays after resizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "seven-interview",
   "metadata": {
    "papermill": {
     "duration": 25.467409,
     "end_time": "2021-08-12T12:51:08.632685",
     "exception": false,
     "start_time": "2021-08-12T12:50:43.165276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/827 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(os\u001b[38;5;241m.\u001b[39mlistdir(folderPath)):\n\u001b[0;32m      7\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folderPath,j))\n\u001b[1;32m----> 8\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(image_size, image_size))\n\u001b[0;32m      9\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     10\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 150\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('Brain-Tumor-Classification-DataSet','Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "for i in labels:\n",
    "    folderPath = os.path.join('Brain-Tumor-Classification-DataSet','Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-chain",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.463376,
     "end_time": "2021-08-12T12:51:09.198072",
     "exception": false,
     "start_time": "2021-08-12T12:51:08.734696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "fig, ax = plt.subplots(1,4,figsize=(20,20))\n",
    "fig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\n",
    "for i in labels:\n",
    "    j=0\n",
    "    while True :\n",
    "        if y_train[j]==i:\n",
    "            ax[k].imshow(X_train[j])\n",
    "            ax[k].set_title(y_train[j])\n",
    "            ax[k].axis('off')\n",
    "            k+=1\n",
    "            break\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-class",
   "metadata": {
    "papermill": {
     "duration": 0.190076,
     "end_time": "2021-08-12T12:51:09.496218",
     "exception": false,
     "start_time": "2021-08-12T12:51:09.306142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-corrections",
   "metadata": {
    "papermill": {
     "duration": 0.129068,
     "end_time": "2021-08-12T12:51:09.741776",
     "exception": false,
     "start_time": "2021-08-12T12:51:09.612708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-standard",
   "metadata": {
    "papermill": {
     "duration": 0.107707,
     "end_time": "2021-08-12T12:51:09.959195",
     "exception": false,
     "start_time": "2021-08-12T12:51:09.851488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dividing the dataset into **Training** and **Testing** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-specialist",
   "metadata": {
    "papermill": {
     "duration": 0.188211,
     "end_time": "2021-08-12T12:51:10.260403",
     "exception": false,
     "start_time": "2021-08-12T12:51:10.072192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-aaron",
   "metadata": {
    "papermill": {
     "duration": 0.157511,
     "end_time": "2021-08-12T12:51:10.534884",
     "exception": false,
     "start_time": "2021-08-12T12:51:10.377373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Performing **One Hot Encoding** on the labels after converting it into numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-survey",
   "metadata": {
    "papermill": {
     "duration": 0.211868,
     "end_time": "2021-08-12T12:51:10.971886",
     "exception": false,
     "start_time": "2021-08-12T12:51:10.760018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.torch.nn.utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.torch.nn.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-script",
   "metadata": {
    "papermill": {
     "duration": 0.116998,
     "end_time": "2021-08-12T12:51:11.235632",
     "exception": false,
     "start_time": "2021-08-12T12:51:11.118634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-basis",
   "metadata": {
    "papermill": {
     "duration": 0.116078,
     "end_time": "2021-08-12T12:51:11.467712",
     "exception": false,
     "start_time": "2021-08-12T12:51:11.351634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-paint",
   "metadata": {
    "papermill": {
     "duration": 0.11674,
     "end_time": "2021-08-12T12:51:11.700567",
     "exception": false,
     "start_time": "2021-08-12T12:51:11.583827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Deep convolutional neural network models may take days or even weeks to train on very large datasets.\n",
    "\n",
    "A way to short-cut this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems.\n",
    "\n",
    "In this notebook, I'll be using the **EfficientNetB0** model which will use the weights from the **ImageNet** dataset.\n",
    "\n",
    "The include_top parameter is set to *False* so that the network doesn't include the top layer/ output layer from the pre-built model which allows us to add our own output layer depending upon our use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-siemens",
   "metadata": {
    "papermill": {
     "duration": 3.880322,
     "end_time": "2021-08-12T12:51:15.701448",
     "exception": false,
     "start_time": "2021-08-12T12:51:11.821126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-cookie",
   "metadata": {
    "papermill": {
     "duration": 0.118098,
     "end_time": "2021-08-12T12:51:15.937340",
     "exception": false,
     "start_time": "2021-08-12T12:51:15.819242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**GlobalAveragePooling2D** -> This layer acts similar to the Max Pooling layer in CNNs, the only difference being is that it uses the Average values instead of the Max value while *pooling*. This really helps in decreasing the computational load on the machine while training.\n",
    "<br><br>\n",
    "**Dropout** -> This layer omits some of the neurons at each step from the layer making the neurons more independent from the neibouring neurons. It helps in avoiding overfitting. Neurons to be ommitted are selected at random. The **rate** parameter is the liklihood of a neuron activation being set to 0, thus dropping out the neuron\n",
    "\n",
    "**Dense** -> This is the output layer which classifies the image into 1 of the 4 possible classes. It uses the **softmax** function which is a generalization of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-bibliography",
   "metadata": {
    "papermill": {
     "duration": 0.153899,
     "end_time": "2021-08-12T12:51:16.208762",
     "exception": false,
     "start_time": "2021-08-12T12:51:16.054863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = effnet.output\n",
    "model = tf.torch.nn.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.torch.nn.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.torch.nn.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.torch.nn.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-sector",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.23051,
     "end_time": "2021-08-12T12:51:16.556376",
     "exception": false,
     "start_time": "2021-08-12T12:51:16.325866",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-leadership",
   "metadata": {
    "papermill": {
     "duration": 0.118417,
     "end_time": "2021-08-12T12:51:16.794471",
     "exception": false,
     "start_time": "2021-08-12T12:51:16.676054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We finally compile our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-bouquet",
   "metadata": {
    "papermill": {
     "duration": 0.140733,
     "end_time": "2021-08-12T12:51:17.053958",
     "exception": false,
     "start_time": "2021-08-12T12:51:16.913225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-preservation",
   "metadata": {
    "papermill": {
     "duration": 0.118001,
     "end_time": "2021-08-12T12:51:17.291111",
     "exception": false,
     "start_time": "2021-08-12T12:51:17.173110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Callbacks** -> Callbacks can help you fix bugs more quickly, and can help you build better models. They can help you visualize how your modelâ€™s training is going, and can even help prevent overfitting by implementing early stopping or customizing the learning rate on each iteration.<br><br>\n",
    "By definition, \"A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\"\n",
    "\n",
    "In this notebook, I'll be using **TensorBoard, ModelCheckpoint and ReduceLROnPlateau** callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-luxury",
   "metadata": {
    "papermill": {
     "duration": 0.467963,
     "end_time": "2021-08-12T12:51:17.879082",
     "exception": false,
     "start_time": "2021-08-12T12:51:17.411119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "checkpoint = ModelCheckpoint(\"effnet.torch.nn\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-addiction",
   "metadata": {
    "papermill": {
     "duration": 0.11741,
     "end_time": "2021-08-12T12:51:18.352758",
     "exception": false,
     "start_time": "2021-08-12T12:51:18.235348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-method",
   "metadata": {
    "papermill": {
     "duration": 0.11789,
     "end_time": "2021-08-12T12:51:18.589027",
     "exception": false,
     "start_time": "2021-08-12T12:51:18.471137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note**: The training takes alot of time! ~ 2 hours for me (Using CPU)<br>\n",
    "Barely took 5 minutes with the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-attention",
   "metadata": {
    "papermill": {
     "duration": 135.614192,
     "end_time": "2021-08-12T12:53:34.321779",
     "exception": false,
     "start_time": "2021-08-12T12:51:18.707587",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-johnson",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.723132,
     "end_time": "2021-08-12T12:53:35.484115",
     "exception": false,
     "start_time": "2021-08-12T12:53:34.760983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "\n",
    "epochs = [i for i in range(12)]\n",
    "fig, ax = plt.subplots(1,2,figsize=(14,7))\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n",
    "\n",
    "sns.despine()\n",
    "ax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
    "           label = 'Training Accuracy')\n",
    "ax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
    "           label = 'Validation Accuracy')\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.despine()\n",
    "ax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
    "           label ='Training Loss')\n",
    "ax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
    "           label = 'Validation Loss')\n",
    "ax[1].legend(frameon=False)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Training & Validation Loss')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-traveler",
   "metadata": {
    "papermill": {
     "duration": 0.407254,
     "end_time": "2021-08-12T12:53:37.100952",
     "exception": false,
     "start_time": "2021-08-12T12:53:36.693698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-serial",
   "metadata": {
    "papermill": {
     "duration": 0.402509,
     "end_time": "2021-08-12T12:53:37.901770",
     "exception": false,
     "start_time": "2021-08-12T12:53:37.499261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I've used the *argmax function* as each row from the prediction array contains four values for the respective labels. The **maximum** value which is in each row depicts the predicted output out of the 4 possible outcomes.<br>\n",
    "So with *argmax*, I'm able to find out the index associated with the predicted outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-dietary",
   "metadata": {
    "papermill": {
     "duration": 2.280852,
     "end_time": "2021-08-12T12:53:40.585432",
     "exception": false,
     "start_time": "2021-08-12T12:53:38.304580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test_new = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-survivor",
   "metadata": {
    "papermill": {
     "duration": 0.455881,
     "end_time": "2021-08-12T12:53:42.246934",
     "exception": false,
     "start_time": "2021-08-12T12:53:41.791053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-universal",
   "metadata": {
    "papermill": {
     "duration": 0.58633,
     "end_time": "2021-08-12T12:53:43.481913",
     "exception": false,
     "start_time": "2021-08-12T12:53:42.895583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this, <br>\n",
    "0 - Glioma Tumor<br>\n",
    "1 - No Tumor<br>\n",
    "2 - Meningioma Tumor<br>\n",
    "3 - Pituitary Tumor<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-links",
   "metadata": {
    "papermill": {
     "duration": 0.417934,
     "end_time": "2021-08-12T12:53:44.303153",
     "exception": false,
     "start_time": "2021-08-12T12:53:43.885219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_new,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-thermal",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.736535,
     "end_time": "2021-08-12T12:53:45.620014",
     "exception": false,
     "start_time": "2021-08-12T12:53:44.883479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(14,7))\n",
    "sns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n",
    "           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\n",
    "fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n",
    "             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d41ec0-0866-41d9-955b-a4a870a2f896",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.736535,
     "end_time": "2021-08-12T12:53:45.620014",
     "exception": false,
     "start_time": "2021-08-12T12:53:44.883479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained model\n",
    "model.save('model.h5')  # Save the model in .h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc9eb1-c3ba-44ed-a9aa-e9be70f07f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide the path to the saved model file\n",
    "FileLink('my_model.h5')  # For Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-great",
   "metadata": {
    "papermill": {
     "duration": 0.374668,
     "end_time": "2021-08-12T12:53:53.314166",
     "exception": false,
     "start_time": "2021-08-12T12:53:52.939498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-catalyst",
   "metadata": {
    "papermill": {
     "duration": 0.373496,
     "end_time": "2021-08-12T12:53:54.060234",
     "exception": false,
     "start_time": "2021-08-12T12:53:53.686738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook, I performed Image Classification with the help of CNN using Transfer Learning which gave an accuracy of around 98%.<br>\n",
    "I also made widgets which can make predictions on an image from your local machine!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 210.990581,
   "end_time": "2021-08-12T12:53:59.113552",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T12:50:28.122971",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "049d38fffd0947189479fcfb288acbe9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FileUploadModel",
      "state": {
       "_counter": 0,
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FileUploadModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "FileUploadView",
       "accept": "",
       "button_style": "",
       "data": [],
       "description": "Upload",
       "description_tooltip": null,
       "disabled": false,
       "error": "",
       "icon": "upload",
       "layout": "IPY_MODEL_e309697a25eb4aa6beff56738f1a5802",
       "metadata": [],
       "multiple": false,
       "style": "IPY_MODEL_d68d1567b4c34f8c8c73374381b50e78"
      }
     },
     "068e88ad7dd04794a734dff5bd0bb4eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "4cb0fcc88674484987d538c002e0add3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d12e5b1d8624a06a09882ef9270a6d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c4b2582b3c941a5b9333f474c61dfa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82b9d62d087d4472acf4bb2cefea6136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ButtonView",
       "button_style": "",
       "description": "Predict",
       "disabled": false,
       "icon": "",
       "layout": "IPY_MODEL_6c4b2582b3c941a5b9333f474c61dfa4",
       "style": "IPY_MODEL_068e88ad7dd04794a734dff5bd0bb4eb",
       "tooltip": ""
      }
     },
     "d68d1567b4c34f8c8c73374381b50e78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ButtonStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "button_color": null,
       "font_weight": ""
      }
     },
     "e14ed34045f8430082a1b37f60497d27": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_4cb0fcc88674484987d538c002e0add3",
       "msg_id": "",
       "outputs": []
      }
     },
     "e309697a25eb4aa6beff56738f1a5802": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb614248e0bb48d6a6c972073893985a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_82b9d62d087d4472acf4bb2cefea6136",
        "IPY_MODEL_e14ed34045f8430082a1b37f60497d27"
       ],
       "layout": "IPY_MODEL_4d12e5b1d8624a06a09882ef9270a6d4"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
